{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Twitter Sentiment Analysis - AIR Project","metadata":{}},{"cell_type":"markdown","source":"**1. Importing libraries and installing tweepy**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.utils import shuffle\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras_preprocessing.sequence import pad_sequences\n\nfrom tensorflow.keras.layers import Conv1D, Bidirectional, LSTM, Dense, Input, Dropout, Flatten, SpatialDropout1D\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\n\nfrom wordcloud import WordCloud\nimport time\nimport itertools\nimport re\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-09T14:13:47.466933Z","iopub.execute_input":"2023-01-09T14:13:47.467299Z","iopub.status.idle":"2023-01-09T14:13:47.591227Z","shell.execute_reply.started":"2023-01-09T14:13:47.467269Z","shell.execute_reply":"2023-01-09T14:13:47.590221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tweepy","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:13:47.593293Z","iopub.execute_input":"2023-01-09T14:13:47.593930Z","iopub.status.idle":"2023-01-09T14:13:58.091239Z","shell.execute_reply.started":"2023-01-09T14:13:47.593893Z","shell.execute_reply":"2023-01-09T14:13:58.090017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tweepy","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:13:58.093942Z","iopub.execute_input":"2023-01-09T14:13:58.094728Z","iopub.status.idle":"2023-01-09T14:13:58.100020Z","shell.execute_reply.started":"2023-01-09T14:13:58.094666Z","shell.execute_reply":"2023-01-09T14:13:58.098938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#twitter API credentials\nconsumerKey = \"V0AbktVHuciimTCOXSgU7Zbfc\"\nconsumerSecret = \"mREamg9BsZoJsIZNwDORE50GS7ZqWM9uAz5roornoIxj46xCgR\"\naccessToken = \"1190269761948663809-ucGSjbsNsAaWerbXotnidWkEaxdc3M\"\naccessTokenSecret = \"1vRd2O2IlGxeLc9BEc2zrimB8q0yCukFUHq7Mx5zSRbiG\"\n\n#create authentication object\nauthenticate = tweepy.OAuthHandler(consumerKey, consumerSecret)\n#Set access token and access token secret\nauthenticate.set_access_token(accessToken, accessTokenSecret)\n#Create the API object while passing in the auth info\napi = tweepy.API(authenticate)\n\n#extract 10 tweets\nposts = api.user_timeline(screen_name = \"BillGates\", count = 10, lang = \"en\", tweet_mode=\"extended\")\nfor tweet in posts:\n    print(tweet.full_text + '\\n')","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:13:58.103774Z","iopub.execute_input":"2023-01-09T14:13:58.104141Z","iopub.status.idle":"2023-01-09T14:13:58.460296Z","shell.execute_reply.started":"2023-01-09T14:13:58.104107Z","shell.execute_reply":"2023-01-09T14:13:58.459259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2. Loading Data**","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/sentiment140/training.1600000.processed.noemoticon.csv', encoding = 'latin', header = None)\ndf.columns = ['sentiment', 'ID', 'date', 'query', 'username', 'tweet']\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:13:58.461520Z","iopub.execute_input":"2023-01-09T14:13:58.461854Z","iopub.status.idle":"2023-01-09T14:14:01.719554Z","shell.execute_reply.started":"2023-01-09T14:13:58.461818Z","shell.execute_reply":"2023-01-09T14:14:01.718579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Only keep the columns needed for sentiment analysis and change sentiment to positive or negative.","metadata":{}},{"cell_type":"code","source":"data = df.drop(['ID', 'date', 'query', 'username'], axis = 1)\nsent = { 0: 'Negative', 4: 'Positive'}\ndef label_decoder(label):\n    return sent[label]\n\ndata.sentiment = data.sentiment.apply(lambda x : label_decoder(x))\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:14:01.721215Z","iopub.execute_input":"2023-01-09T14:14:01.721608Z","iopub.status.idle":"2023-01-09T14:14:02.174652Z","shell.execute_reply.started":"2023-01-09T14:14:01.721571Z","shell.execute_reply":"2023-01-09T14:14:02.173720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\nsns.countplot(data['sentiment'])\nprint(data['sentiment'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:14:02.176237Z","iopub.execute_input":"2023-01-09T14:14:02.176592Z","iopub.status.idle":"2023-01-09T14:14:03.165548Z","shell.execute_reply.started":"2023-01-09T14:14:02.176556Z","shell.execute_reply":"2023-01-09T14:14:03.164637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3. Preprocessing**","metadata":{}},{"cell_type":"code","source":"stop_words = stopwords.words('english')\nstemmer = SnowballStemmer('english')\ntext_cleaning_re = '@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+'\n\ndef preprocess(text, stem = False):\n    text = re.sub(text_cleaning_re, ' ', str(text).lower()).strip()\n    text = re.sub(r'<3', '<heart>', text)\n    text = re.sub(r\"[8:=;]['`\\-]?[)d]+\", '<smile>', text)\n    text = re.sub(r\"[8:=;]['`\\-]?\\(+\", '<sadface>', text)\n    text = re.sub(r\"[8:=;]['`\\-]?[\\/|l*]\", '<neutralface>', text)\n    text = re.sub(r\"[8:=;]['`\\-]?p+\", '<lolface>', text)\n    text = re.sub(\"[^a-z0-9<>]\", ' ', text)\n    tokens =[]\n    for token in text.split():\n        if token not in stop_words:\n            if stem:\n                tokens.append(stemmer.stem(token))\n            else:\n                tokens.append(token)\n    return ' '.join(tokens)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:14:03.168587Z","iopub.execute_input":"2023-01-09T14:14:03.168907Z","iopub.status.idle":"2023-01-09T14:14:03.178408Z","shell.execute_reply.started":"2023-01-09T14:14:03.168879Z","shell.execute_reply":"2023-01-09T14:14:03.177191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test a tweet to see the difference before and after preprocessing","metadata":{}},{"cell_type":"code","source":"data.tweet[24821]","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:14:03.180042Z","iopub.execute_input":"2023-01-09T14:14:03.180483Z","iopub.status.idle":"2023-01-09T14:14:03.191366Z","shell.execute_reply.started":"2023-01-09T14:14:03.180439Z","shell.execute_reply":"2023-01-09T14:14:03.190232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocess(data.tweet[24821], True)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:14:03.196594Z","iopub.execute_input":"2023-01-09T14:14:03.196887Z","iopub.status.idle":"2023-01-09T14:14:03.204824Z","shell.execute_reply.started":"2023-01-09T14:14:03.196861Z","shell.execute_reply":"2023-01-09T14:14:03.203752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Apply preprocessing to all the data","metadata":{}},{"cell_type":"code","source":"data.tweet = data.tweet.apply(lambda x : preprocess(x))\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:14:03.206205Z","iopub.execute_input":"2023-01-09T14:14:03.206955Z","iopub.status.idle":"2023-01-09T14:15:12.784000Z","shell.execute_reply.started":"2023-01-09T14:14:03.206909Z","shell.execute_reply":"2023-01-09T14:15:12.782885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pull data about specific topics to and see how many tweets are positive versus negative about this topic","metadata":{}},{"cell_type":"code","source":"data = shuffle(data)\nsearchWords = '|'.join(['sport', 'player', 'game', 'ball', 'score', 'winner'])\nfiltered = data[data['tweet'].str.contains(searchWords, case=False)]\npd.set_option('display.max_colwidth', 0)\nprint(\"Amount of positive tweets:\", filtered['sentiment'].value_counts()['Positive'])\nprint(\"Amount of negative tweets:\", filtered['sentiment'].value_counts()['Negative'])\nfiltered.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:15:12.785434Z","iopub.execute_input":"2023-01-09T14:15:12.786132Z","iopub.status.idle":"2023-01-09T14:15:20.293648Z","shell.execute_reply.started":"2023-01-09T14:15:12.786092Z","shell.execute_reply":"2023-01-09T14:15:20.292734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"searchWords = '|'.join(['job', 'work', 'weekday', 'commute'])\nfiltered1 = data[data['tweet'].str.contains(searchWords, case=False)]\nprint(\"Amount of positive tweets:\", filtered1['sentiment'].value_counts()['Positive'])\nprint(\"Amount of negative tweets:\", filtered1['sentiment'].value_counts()['Negative'])\npd.set_option('display.max_colwidth', 0)\nfiltered1.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:15:20.295511Z","iopub.execute_input":"2023-01-09T14:15:20.296068Z","iopub.status.idle":"2023-01-09T14:15:24.899047Z","shell.execute_reply.started":"2023-01-09T14:15:20.296032Z","shell.execute_reply":"2023-01-09T14:15:24.898042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"searchWords = '|'.join(['Obama', 'Trump', 'politics', 'president', 'election'])\nfiltered2 = data[data['tweet'].str.contains(searchWords, case=False)]\nprint(\"Amount of positive tweets:\", filtered2['sentiment'].value_counts()['Positive'])\nprint(\"Amount of negative tweets:\", filtered2['sentiment'].value_counts()['Negative'])\npd.set_option('display.max_colwidth', 0)\nfiltered2.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:15:24.900718Z","iopub.execute_input":"2023-01-09T14:15:24.901427Z","iopub.status.idle":"2023-01-09T14:15:30.549740Z","shell.execute_reply.started":"2023-01-09T14:15:24.901389Z","shell.execute_reply":"2023-01-09T14:15:30.548753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processedtext = list(data.tweet)\ndata_pos = processedtext[800000:]\ndata_neg = processedtext[:800000]","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:15:30.551412Z","iopub.execute_input":"2023-01-09T14:15:30.552140Z","iopub.status.idle":"2023-01-09T14:15:30.889485Z","shell.execute_reply.started":"2023-01-09T14:15:30.552102Z","shell.execute_reply":"2023-01-09T14:15:30.888387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_cloud = WordCloud(max_words = 1000 , width = 1000 , height = 600,\n              collocations=False).generate(\" \".join(data_pos))\nplt.figure(figsize = (20,20))\nplt.imshow(word_cloud)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:15:30.891173Z","iopub.execute_input":"2023-01-09T14:15:30.891545Z","iopub.status.idle":"2023-01-09T14:15:43.159414Z","shell.execute_reply.started":"2023-01-09T14:15:30.891507Z","shell.execute_reply":"2023-01-09T14:15:43.158605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wc = WordCloud(max_words = 1000 , width = 1000 , height = 600,\n              collocations=False).generate(\" \".join(data_neg))\nplt.figure(figsize = (20,20))\nplt.imshow(wc)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:15:43.160671Z","iopub.execute_input":"2023-01-09T14:15:43.161621Z","iopub.status.idle":"2023-01-09T14:15:55.701572Z","shell.execute_reply.started":"2023-01-09T14:15:43.161585Z","shell.execute_reply":"2023-01-09T14:15:55.700729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**4. Split data into training and testing sets**","metadata":{}},{"cell_type":"code","source":"Train_size = 0.8\nmax_words = 100000\nmax_length = 30","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:15:55.702856Z","iopub.execute_input":"2023-01-09T14:15:55.703816Z","iopub.status.idle":"2023-01-09T14:15:55.708739Z","shell.execute_reply.started":"2023-01-09T14:15:55.703780Z","shell.execute_reply":"2023-01-09T14:15:55.707977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data, test_data = train_test_split(data, test_size = 1 - Train_size, random_state = 5)\nprint('size of training data :', len(train_data))\nprint('size of testing data :',len(test_data))","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:15:55.709973Z","iopub.execute_input":"2023-01-09T14:15:55.710953Z","iopub.status.idle":"2023-01-09T14:15:56.010735Z","shell.execute_reply.started":"2023-01-09T14:15:55.710919Z","shell.execute_reply":"2023-01-09T14:15:56.009613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:15:56.012310Z","iopub.execute_input":"2023-01-09T14:15:56.012707Z","iopub.status.idle":"2023-01-09T14:15:56.022769Z","shell.execute_reply.started":"2023-01-09T14:15:56.012653Z","shell.execute_reply":"2023-01-09T14:15:56.021669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(train_data.tweet)\n\nword_index = tokenizer.word_index\nvocab_size = len(word_index)\nprint('VOCAB_SIZE :', vocab_size)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:15:56.024567Z","iopub.execute_input":"2023-01-09T14:15:56.024970Z","iopub.status.idle":"2023-01-09T14:16:13.942104Z","shell.execute_reply.started":"2023-01-09T14:15:56.024934Z","shell.execute_reply":"2023-01-09T14:16:13.940897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = pad_sequences(tokenizer.texts_to_sequences(train_data.tweet), maxlen = max_length)\nx_test = pad_sequences(tokenizer.texts_to_sequences(test_data.tweet), maxlen = max_length)\n\nprint('training x shape :', x_train.shape)\nprint('testing x shape :', x_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:16:13.943618Z","iopub.execute_input":"2023-01-09T14:16:13.944225Z","iopub.status.idle":"2023-01-09T14:16:39.771472Z","shell.execute_reply.started":"2023-01-09T14:16:13.944185Z","shell.execute_reply":"2023-01-09T14:16:39.770183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = LabelEncoder()\nencoder.fit(train_data.sentiment.to_list())\n\ny_train = encoder.transform(train_data.sentiment.tolist())\ny_test = encoder.transform(test_data.sentiment.tolist())\n\ny_train = y_train.reshape(1280000,1)\ny_test = y_test.reshape(320000,1)\n\nprint('y_train shape :', y_train.shape)\nprint('y_test shape :', y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:16:39.773547Z","iopub.execute_input":"2023-01-09T14:16:39.774549Z","iopub.status.idle":"2023-01-09T14:16:41.027612Z","shell.execute_reply.started":"2023-01-09T14:16:39.774508Z","shell.execute_reply":"2023-01-09T14:16:41.026568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Import word embeddings and create representations of word vectors for the tweets in our dataset. ","metadata":{}},{"cell_type":"code","source":"!wget http://nlp.stanford.edu/data/glove.6B.zip\n!unzip glove.6B.zip","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:16:41.029019Z","iopub.execute_input":"2023-01-09T14:16:41.029645Z","iopub.status.idle":"2023-01-09T14:22:50.467184Z","shell.execute_reply.started":"2023-01-09T14:16:41.029606Z","shell.execute_reply":"2023-01-09T14:22:50.465984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GLOVE_EMB = './glove.6B.300d.txt'\nEMBEDDING_DIM = 300\nLR = 1e-3\nBATCH_SIZE = 1024\nEPOCHS = 12\nMODEL_PATH = '.../output/kaggle/working/best_model.hdf5'","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:22:50.469446Z","iopub.execute_input":"2023-01-09T14:22:50.469882Z","iopub.status.idle":"2023-01-09T14:22:50.476166Z","shell.execute_reply.started":"2023-01-09T14:22:50.469836Z","shell.execute_reply":"2023-01-09T14:22:50.474936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeddings_index = {}\nfile = open(GLOVE_EMB)\nfor line in file:\n    values = line.split()\n    word = value = values[0]\n    coef = np.asarray(values[1:],dtype = 'float32')\n    embeddings_index[word] = coef\n    \nfile.close()\nprint('Found {} word vectors'.format(len(embeddings_index)))","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:22:50.478197Z","iopub.execute_input":"2023-01-09T14:22:50.478698Z","iopub.status.idle":"2023-01-09T14:23:11.537622Z","shell.execute_reply.started":"2023-01-09T14:22:50.478646Z","shell.execute_reply":"2023-01-09T14:23:11.536560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:23:11.539209Z","iopub.execute_input":"2023-01-09T14:23:11.539563Z","iopub.status.idle":"2023-01-09T14:23:12.232473Z","shell.execute_reply.started":"2023-01-09T14:23:11.539527Z","shell.execute_reply":"2023-01-09T14:23:12.231417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**5. Begin Training**","metadata":{}},{"cell_type":"code","source":"embedding_layer = tf.keras.layers.Embedding(vocab_size,\n                                           EMBEDDING_DIM,\n                                           weights = [embedding_matrix],\n                                           input_length = max_length,\n                                           trainable = False)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:23:12.241012Z","iopub.execute_input":"2023-01-09T14:23:12.245782Z","iopub.status.idle":"2023-01-09T14:23:12.254539Z","shell.execute_reply.started":"2023-01-09T14:23:12.245737Z","shell.execute_reply":"2023-01-09T14:23:12.253533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequence_input = Input(shape = (max_length), dtype = 'int32')\nembedding_sequences = embedding_layer(sequence_input)\nx = SpatialDropout1D(0.2)(embedding_sequences)\nx = Conv1D(64, 5, activation = 'relu')(x)\nx = Bidirectional(LSTM(64, dropout = 0.2, recurrent_dropout = 0.2))(x)\nx = Dense(512, activation = 'relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(512, activation = 'relu')(x)\noutputs = Dense(1, activation = 'sigmoid')(x)\nmodel = tf.keras.Model(sequence_input, outputs)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:23:12.255758Z","iopub.execute_input":"2023-01-09T14:23:12.256171Z","iopub.status.idle":"2023-01-09T14:23:13.509383Z","shell.execute_reply.started":"2023-01-09T14:23:12.256134Z","shell.execute_reply":"2023-01-09T14:23:13.508463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:23:13.510654Z","iopub.execute_input":"2023-01-09T14:23:13.511494Z","iopub.status.idle":"2023-01-09T14:23:13.519949Z","shell.execute_reply.started":"2023-01-09T14:23:13.511457Z","shell.execute_reply":"2023-01-09T14:23:13.518975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = Adam(learning_rate = LR),\n             loss ='binary_crossentropy',\n             metrics = ['accuracy'])\n\nreduction = ReduceLROnPlateau(factor = 0.1,\n                                min_lr = 0.0001,\n                                monitor = 'val_loss',\n                                verbose = 1)\nhistory = model.fit(x_train,\n                   y_train,\n                   batch_size = BATCH_SIZE,\n                   epochs = EPOCHS,\n                   validation_data = (x_test, y_test),\n                   callbacks = [reduction])","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:23:13.521460Z","iopub.execute_input":"2023-01-09T14:23:13.521844Z","iopub.status.idle":"2023-01-09T14:48:11.171284Z","shell.execute_reply.started":"2023-01-09T14:23:13.521800Z","shell.execute_reply":"2023-01-09T14:48:11.170194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(acc))\n\n\nplt.figure(figsize = (9,4))\nplt.plot(acc, color = 'green', label = 'Training Accuracy')\nplt.plot(val_acc, color = 'red', label = ' Validation Accuracy')\nplt.legend()\n\nplt.figure(figsize= (9,4))\nplt.plot(loss,color = 'green', label = 'Training Loss')\nplt.plot(val_loss, color = 'red', label = ' Validation Loss')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:48:11.172951Z","iopub.execute_input":"2023-01-09T14:48:11.173624Z","iopub.status.idle":"2023-01-09T14:48:11.572654Z","shell.execute_reply.started":"2023-01-09T14:48:11.173583Z","shell.execute_reply":"2023-01-09T14:48:11.571626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**6. Accuracy and Predictions**","metadata":{}},{"cell_type":"code","source":"def decode_sentiment(score):\n    return 'Positive' if score > 0.5 else 'Negative'\n        \nscores = model.predict(x_test, verbose = 1, batch_size = 10000)\ny_pred_D = [decode_sentiment(score) for score in scores]","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:48:11.574060Z","iopub.execute_input":"2023-01-09T14:48:11.574509Z","iopub.status.idle":"2023-01-09T14:48:13.681519Z","shell.execute_reply.started":"2023-01-09T14:48:11.574471Z","shell.execute_reply":"2023-01-09T14:48:13.680562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize = False,\n                          title = 'Confusion Matrix',\n                          cmap = plt.cm.Blues):\n    plt.imshow(cm, interpolation = 'nearest', cmap =cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes,rotation = 30)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n             horizontalalignment= 'center',\n             color = \"white\" if cm[i,j]>thresh else \"black\")\n        \n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('predicted label')\n\ncnf_matrix = confusion_matrix(test_data.sentiment.tolist(), y_pred_D)\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes = test_data.sentiment.unique(), title = 'confusion matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:48:13.683081Z","iopub.execute_input":"2023-01-09T14:48:13.683488Z","iopub.status.idle":"2023-01-09T14:48:15.329676Z","shell.execute_reply.started":"2023-01-09T14:48:13.683449Z","shell.execute_reply":"2023-01-09T14:48:15.328671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = max(acc)\nprint('Accuracy of model :', accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:48:15.331208Z","iopub.execute_input":"2023-01-09T14:48:15.331554Z","iopub.status.idle":"2023-01-09T14:48:15.337779Z","shell.execute_reply.started":"2023-01-09T14:48:15.331517Z","shell.execute_reply":"2023-01-09T14:48:15.336583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Precision, recall, and f1-score of the model","metadata":{}},{"cell_type":"code","source":"print(classification_report(list(test_data.sentiment), y_pred_D))","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:48:15.339368Z","iopub.execute_input":"2023-01-09T14:48:15.340023Z","iopub.status.idle":"2023-01-09T14:48:20.369976Z","shell.execute_reply.started":"2023-01-09T14:48:15.339986Z","shell.execute_reply":"2023-01-09T14:48:20.368734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def final_sentiment(score):\n    if score > 0.6:\n            return 'Positive'\n    elif (score > 0.4 and score < 0.6):\n            return 'Neutral'\n    else:\n            return'Negative'\n        \ndef pred(text):\n    start_at = time.time()\n    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=max_length) \n    score = model.predict([x_test])[0]\n    label = final_sentiment(score)\n\n    return {\"label\": label, \"score\": float(score),\n       \"elapsed_time\": time.time()-start_at}","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:48:20.371593Z","iopub.execute_input":"2023-01-09T14:48:20.372291Z","iopub.status.idle":"2023-01-09T14:48:20.380593Z","shell.execute_reply.started":"2023-01-09T14:48:20.372250Z","shell.execute_reply":"2023-01-09T14:48:20.379192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**7. Test model on actual tweets**","metadata":{}},{"cell_type":"markdown","source":"Pull tweets from a certain user (Elon Musk)","metadata":{}},{"cell_type":"code","source":"posts = api.user_timeline(screen_name = \"elonmusk\", count = 5, lang = \"en\", tweet_mode=\"extended\")\n\nsums = 0.\ncounter = 0\npos = 0\nneg = 0\nneu = 0\n\nprint('--------Tweets: ')\nprint('\\n')\n\nfor tweet in posts:\n    print(tweet.full_text)\n    prediction = pred(tweet.full_text)\n    \n    temp = prediction.get('score')\n    sums += temp\n    counter += 1\n    \n    temp2 = prediction.get('label')\n    if temp2 == 'Positive':\n        pos += 1\n    elif temp2 == 'Negative':\n        neg += 1\n    else:\n        neu += 1\n    print(prediction)    \n    print('\\n')\n    \nprint('---------------------------------------------------------------------------------------')\nprint('There are '+ str(pos)+' positive tweets, '+str(neg) +' negative tweets, and '+str(neu) +' neutral tweets')   \navg = sums/counter\nprint('The average score of all the retrieved tweets is ' +str(avg))\nif avg > 0.6:\n    print('The final grade is therefore positive.')\nelif (avg > 0.4 and avg < 0.6):\n    print('The final grade is therefore neutral.')\nelse:\n    print('The final grade is therefore negative.')","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:48:20.382523Z","iopub.execute_input":"2023-01-09T14:48:20.382930Z","iopub.status.idle":"2023-01-09T14:48:21.233330Z","shell.execute_reply.started":"2023-01-09T14:48:20.382891Z","shell.execute_reply":"2023-01-09T14:48:21.232359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pull tweets about a certain topic (sports)","metadata":{}},{"cell_type":"code","source":"search_term = '|'.join(['sport', 'player', 'game', 'ball', 'score', 'winner'])\ntweet_amount = 5\nsums = 0.\ncounter = 0\npos = 0\nneg = 0\nneu = 0\ntweets = tweepy.Cursor(api.search_tweets, q = search_term, lang = 'en').items(tweet_amount)\nprint('--------Tweets: ')\nprint('\\n')\nfor tweet in tweets:\n    print(tweet.text)\n    prediction = pred(tweet.text)\n    \n    temp = prediction.get('score')\n    sums += temp\n    counter += 1\n    \n    temp2 = prediction.get('label')\n    if temp2 == 'Positive':\n        pos += 1\n    elif temp2 == 'Negative':\n        neg += 1\n    else:\n        neu += 1\n    print(prediction)    \n    print('\\n')\nprint('---------------------------------------------------------------------------------------')\nprint('There are '+ str(pos)+' positive tweets, '+str(neg) +' negative tweets, and '+str(neu) +' neutral tweets')   \navg = sums/counter\nprint('The average score of all the retrieved tweets is ' +str(avg)) \nif avg > 0.6:\n    print('The final grade is therefore positive')\nelif (avg > 0.4 and avg < 0.6):\n    print('The final grade is therefore neutral')\nelse:\n    print('The final grade is therefore negative')","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:49:03.861280Z","iopub.execute_input":"2023-01-09T14:49:03.861650Z","iopub.status.idle":"2023-01-09T14:49:04.134984Z","shell.execute_reply.started":"2023-01-09T14:49:03.861620Z","shell.execute_reply":"2023-01-09T14:49:04.133620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pull tweets with certain queries (cars)","metadata":{}},{"cell_type":"code","source":"client = tweepy.Client(bearer_token = 'AAAAAAAAAAAAAAAAAAAAADvCkQEAAAAAqBldguiK%2FewFmwE1Cpd1UbQrlew%3D4Ysvdx21ITFfLHDHTL5nnV8q5KCNJ8dOLrYf23yIE8S3OOnCvw')\nquery = '#cars -is:retweet lang:en'\ntweets = client.search_recent_tweets(query=query, tweet_fields=['context_annotations', 'created_at'], max_results=10)\nsums = 0.\ncounter = 0\npos = 0\nneg = 0\nneu = 0\nfor tweet in tweets.data:\n    print(tweet.text)\n    prediction = pred(tweet.text)\n    \n    temp =prediction.get('score')\n    sums += temp\n    counter += 1\n    \n    temp2 = prediction.get('label')\n    if temp2 == 'Positive':\n        pos += 1\n    elif temp2 == 'Negative':\n        neg += 1\n    else:\n        neu += 1\n    print(prediction)    \n    print('\\n')\nprint('---------------------------------------------------------------------------------------')\nprint('There are '+ str(pos)+' positive tweets, '+str(neg) +' negative tweets, and '+str(neu) +' neutral tweets')   \navg = sums/counter\nprint('The average score of all the retrieved tweets is ' +str(avg)) \nif avg > 0.6:\n    print('The final grade is therefore positive')\nelif (avg > 0.4 and avg < 0.6):\n    print('The final grade is therefore neutral')\nelse:\n    print('The final grade is therefore negative')","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:48:45.600596Z","iopub.execute_input":"2023-01-09T14:48:45.601020Z","iopub.status.idle":"2023-01-09T14:48:46.472936Z","shell.execute_reply.started":"2023-01-09T14:48:45.600986Z","shell.execute_reply":"2023-01-09T14:48:46.471952Z"},"trusted":true},"execution_count":null,"outputs":[]}]}